# 审稿人建议实验计划

## 实验状态总览

| 实验编号 | 实验名称 | 状态 | 优先级 | 预计工作量 |
|---------|---------|------|--------|-----------|
| 1 | 构建更公平的强基线（AnalogSeeker + Ours） | ✅ 已完成 | - | - |
| 2 | CoT vs Expert Guidance对比 | 🔄 可执行 | 高 | 中等 |
| 3 | 路由策略敏感性分析 | 🔄 可执行 | 高 | 中等 |
| 4 | 泛化性验证（其他模型） | ⚠️ 需资源 | 中 | 高 |
| 5 | 失败案例分析 | 🔄 可执行 | 高 | 低 |

---

## 实验1: 构建更公平的强基线 ✅

**状态**: 已完成

**已完成内容**:
- ✅ AnalogSeeker + Ours: 在AnalogSeeker上应用相同的优化策略
- ✅ 结果文件: `results/analogseeker_before_after_comparison_results.json`
- ✅ 分析文档: `docs/ReasoningV与Analogseeker优化对比完整总结.md`

**关键发现**:
- ReasoningV优化后: 79.01% → 86.66% (+7.65%)
- AnalogSeeker优化后: 84.97% → 84.97% (0.00%)
- 证明推理模型的"逻辑中心预训练"确实比SFT模型提供了更好的底层推理支架

---

## 实验2: CoT vs Expert Guidance对比 🔄

### 实验目标

证明通用的CoT（"Let's think step by step"）不足以解决模拟电路问题，必须结合领域特定的结构化思维（Expert Strategy）。

### 实验设计

**对比组**:
1. **Baseline**: 标准配置（无提示词优化）
2. **Generic CoT**: 只加 "Let's think step by step" 的通用思维链
3. **Expert Guidance**: 当前的专家指导策略（Few-shot + 结构化Checklist）

**测试任务**: LDO, Comparator, Caption（这些任务有明显提升）

### 预期结果

- Generic CoT应该比Baseline有提升，但不如Expert Guidance
- Expert Guidance显著优于Generic CoT，证明领域特定知识的重要性

### 实施步骤

1. 创建CoT测试脚本
2. 在LDO、Comparator、Caption任务上测试
3. 对比三种策略的准确率
4. 分析差异原因

---

## 实验3: 路由策略敏感性分析 🔄

### 实验目标

1. 展示Router分类错误的案例和影响
2. 证明"对症下药"的重要性（强制使用错误策略的性能损失）

### 实验设计

#### 3.1 混淆矩阵分析

**方法**:
- 对TQA任务的所有问题，手动标注真实类型
- 使用Router自动分类
- 构建混淆矩阵，展示分类准确性

**分析内容**:
- Router分类准确率
- 各类别之间的混淆情况
- 分类错误对最终准确率的影响

#### 3.2 错误策略性能损失分析

**方法**:
- 选择典型问题（事实题、推理题、计算题、分析题、比较题各选5-10个）
- 强制使用错误的策略（例如对计算题使用Expert Strategy，对分析题使用Precise Strategy）
- 对比正确策略 vs 错误策略的准确率

**量化指标**:
- 准确率下降幅度
- 错误策略导致的额外错误数

### 实施步骤

1. 创建Router混淆矩阵分析脚本
2. 创建错误策略测试脚本
3. 运行测试并生成报告

---

## 实验4: 泛化性验证（其他模型）⚠️

### 实验目标

证明提出的方法论具有普适性，而不仅仅是针对特定模型调参的结果。

### 实验设计

**候选模型**:
- Llama-3-70B-Instruct（如果有资源）
- Qwen-2.5-Coder/Math（如果有资源）
- 或其他可用的通用推理模型

**测试内容**:
- 应用相同的优化框架（Few-shot + Expert Guidance + Router）
- 对比优化前后的准确率提升

### 预期结果

如果框架在其他模型上也能带来显著提升（哪怕绝对分数不如ReasoningV），就能证明这是一套通用的"Prompt Engineering Framework for EDA"。

### 实施限制

- ⚠️ 需要其他模型的访问权限
- ⚠️ 需要额外的计算资源
- ⚠️ 可能需要较长时间

### 建议

- 如果资源有限，可以先在文档中说明这是未来工作
- 或者选择较小的模型进行验证

---

## 实验5: 失败案例分析 🔄

### 实验目标

展示AnalogSeeker（SFT模型）产生幻觉或逻辑错误的具体Case，并对比展示ReasoningV如何通过Few-shot或Checklist避免这个错误。

### 实验设计

**分析内容**:
1. **错误案例收集**:
   - 找出AnalogSeeker答错但ReasoningV答对的题目
   - 找出ReasoningV优化前答错但优化后答对的题目

2. **案例分析**:
   - 展示AnalogSeeker的错误回答和推理过程
   - 展示ReasoningV（优化后）的正确回答和推理过程
   - 分析为什么Few-shot或Checklist帮助避免了错误

3. **错误类型分类**:
   - 幻觉错误（Hallucination）
   - 逻辑错误（Logical Error）
   - 灾难性遗忘（Catastrophic Forgetting）
   - 选项偏见（Option Bias）

### 实施步骤

1. 对比两个模型的错误答案
2. 选择典型错误案例（每个类型1-2个）
3. 详细分析错误原因和优化策略如何避免错误
4. 生成可视化报告

---

## 实施优先级

### 高优先级（必须完成）

1. ✅ **实验1**: 已完成
2. 🔄 **实验2**: CoT vs Expert Guidance - 证明领域特定知识的重要性
3. 🔄 **实验3**: 路由策略敏感性分析 - 证明Router的必要性
4. 🔄 **实验5**: 失败案例分析 - 提供具体的错误案例对比

### 中优先级（建议完成）

5. ⚠️ **实验4**: 泛化性验证 - 如果资源允许

---

## 下一步行动

1. **立即开始**: 实验2（CoT对比）和实验5（失败案例分析）
2. **随后进行**: 实验3（路由策略敏感性分析）
3. **资源允许时**: 实验4（泛化性验证）

---

**文档创建时间**: 2025-12-07  
**最后更新**: 2025-12-07

